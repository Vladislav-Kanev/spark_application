{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, IntegerType, ByteType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "from data_preprocess import (\n",
    "    cast_df_values,\n",
    "    encode_string_column,\n",
    "    get_data_shape,\n",
    "    count_nans,\n",
    "    count_col_values,\n",
    "    assemble_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/06/24 15:48:12 WARN Utils: Your hostname, DESKTOP-NTRA1ID resolves to a loopback address: 127.0.1.1; using 172.22.18.100 instead (on interface eth0)\n",
      "24/06/24 15:48:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/24 15:48:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.18.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>model</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f27641a9810>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"model\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"../dataset/PS_20174392719_1491204439457_log.csv\", header=True)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "\n",
      "step\n",
      "type\n",
      "amount\n",
      "nameOrig\n",
      "oldbalanceOrg\n",
      "newbalanceOrig\n",
      "nameDest\n",
      "oldbalanceDest\n",
      "newbalanceDest\n",
      "isFraud\n",
      "isFlaggedFraud\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns\n",
    "print(\"Columns:\", \"\\n\".join(columns), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=============================>                             (2 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 6362620,\n",
      "Number of features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rows, cols = get_data_shape(data)\n",
    "print(f\"Number of rows: {rows},\\nNumber of features: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[step: bigint, type: bigint, amount: bigint, nameOrig: bigint, oldbalanceOrg: bigint, newbalanceOrig: bigint, nameDest: bigint, oldbalanceDest: bigint, newbalanceDest: bigint, isFraud: bigint, isFlaggedFraud: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count\n",
    "\n",
    "data.select([count(when(isnan(c), c)).alias(c) for c in data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|   0|   0|     0|       0|            0|             0|       0|             0|             0|      0|             0|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_nans(data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = [\n",
    "    \"amount\",\n",
    "    \"oldbalanceOrg\",\n",
    "    \"newbalanceOrig\",\n",
    "    \"oldbalanceDest\",\n",
    "    \"newbalanceDest\",\n",
    "]\n",
    "data = cast_df_values(data, float_columns, newType=FloatType)\n",
    "\n",
    "int_columns = [\"step\", \"isFraud\", \"isFlaggedFraud\"]\n",
    "data = cast_df_values(data, int_columns, newType=IntegerType)\n",
    "\n",
    "byte_columns = [\n",
    "    \"nameOrig\",\n",
    "    \"nameDest\"\n",
    "]\n",
    "data = cast_df_values(data, byte_columns, newType=ByteType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[step: int, type: string, amount: float, nameOrig: tinyint, oldbalanceOrg: float, newbalanceOrig: float, nameDest: tinyint, oldbalanceDest: float, newbalanceDest: float, isFraud: int, isFlaggedFraud: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    type|  count|\n",
      "+--------+-------+\n",
      "|TRANSFER| 532909|\n",
      "| CASH_IN|1399284|\n",
      "|CASH_OUT|2237500|\n",
      "| PAYMENT|2151495|\n",
      "|   DEBIT|  41432|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_col_values(data, \"type\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      1|   8213|\n",
      "|      0|6354407|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_col_values(data, \"isFraud\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+---------+\n",
      "|step|    type|  amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|type_indx|\n",
      "+----+--------+--------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+---------+\n",
      "|   1| PAYMENT| 9839.64|    NULL|     170136.0|     160296.36|    NULL|           0.0|           0.0|      0|             0|      1.0|\n",
      "|   1| PAYMENT| 1864.28|    NULL|      21249.0|      19384.72|    NULL|           0.0|           0.0|      0|             0|      1.0|\n",
      "|   1|TRANSFER|   181.0|    NULL|        181.0|           0.0|    NULL|           0.0|           0.0|      1|             0|      3.0|\n",
      "|   1|CASH_OUT|   181.0|    NULL|        181.0|           0.0|    NULL|       21182.0|           0.0|      1|             0|      0.0|\n",
      "|   1| PAYMENT|11668.14|    NULL|      41554.0|      29885.86|    NULL|           0.0|           0.0|      0|             0|      1.0|\n",
      "+----+--------+--------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = encode_string_column(data, \"type\", \"type_indx\")\n",
    "\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"type_indx\",\n",
    "    \"amount\",\n",
    "    \"oldbalanceOrg\",\n",
    "    \"newbalanceOrig\",\n",
    "    \"newbalanceDest\",\n",
    "    \"oldbalanceDest\",\n",
    "]\n",
    "\n",
    "target = \"isFraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = assemble_cols(data, features, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data.randomSplit(weights=[0.8,0.2], seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/24 15:48:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/06/24 15:49:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/06/24 15:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      1|   6614|\n",
      "|      0|5082990|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_col_values(train_df, \"isFraud\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/24 15:49:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/06/24 15:49:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/06/24 15:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 21:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      1|   1599|\n",
      "|      0|1271417|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_col_values(test_df, \"isFraud\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/24 15:50:55 WARN MemoryStore: Not enough space to cache rdd_95_3 in memory! (computed 144.3 MiB so far)\n",
      "24/06/24 15:50:55 WARN BlockManager: Persisting block rdd_95_3 to disk instead.\n",
      "24/06/24 15:50:58 WARN MemoryStore: Not enough space to cache rdd_95_0 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:50:59 WARN MemoryStore: Not enough space to cache rdd_95_1 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:01 WARN MemoryStore: Not enough space to cache rdd_95_2 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:03 WARN MemoryStore: Not enough space to cache rdd_95_0 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:05 WARN MemoryStore: Not enough space to cache rdd_95_1 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:07 WARN MemoryStore: Not enough space to cache rdd_95_2 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:10 WARN MemoryStore: Not enough space to cache rdd_95_0 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:13 WARN MemoryStore: Not enough space to cache rdd_95_1 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:15 WARN MemoryStore: Not enough space to cache rdd_95_2 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:18 WARN MemoryStore: Not enough space to cache rdd_95_0 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:21 WARN MemoryStore: Not enough space to cache rdd_95_1 in memory! (computed 228.0 MiB so far)\n",
      "24/06/24 15:51:23 WARN MemoryStore: Not enough space to cache rdd_95_2 in memory! (computed 228.0 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"isFraud\")\n",
    "model = clf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994831172585419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.transform(test_df)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"isFraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../model/random_forest_classifier\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
